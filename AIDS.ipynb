{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8098378-b20c-4ac1-9a1f-80f80e055b52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ucimlrepo in /home/rkhan5/.local/lib/python3.11/site-packages (0.0.7)\n",
      "Requirement already satisfied: numpy in /share/apps/rc/software/Anaconda3/2023.07-2/lib/python3.11/site-packages (1.24.3)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.2.tar.gz (20.5 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[19 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[36m\u001b[1m+ /share/apps/rc/software/Anaconda3/2023.07-2/bin/python /local/pip-install-d_bwie82/numpy_dc36abcfd7c74a21ac2b283dc48b0662/vendored-meson/meson/meson.py setup /local/pip-install-d_bwie82/numpy_dc36abcfd7c74a21ac2b283dc48b0662 /local/pip-install-d_bwie82/numpy_dc36abcfd7c74a21ac2b283dc48b0662/.mesonpy-g8kfwdri -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/local/pip-install-d_bwie82/numpy_dc36abcfd7c74a21ac2b283dc48b0662/.mesonpy-g8kfwdri/meson-python-native-file.ini\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The Meson build system\n",
      "  \u001b[31m   \u001b[0m Version: 1.6.1\n",
      "  \u001b[31m   \u001b[0m Source dir: /local/pip-install-d_bwie82/numpy_dc36abcfd7c74a21ac2b283dc48b0662\n",
      "  \u001b[31m   \u001b[0m Build dir: /local/pip-install-d_bwie82/numpy_dc36abcfd7c74a21ac2b283dc48b0662/.mesonpy-g8kfwdri\n",
      "  \u001b[31m   \u001b[0m Build type: native build\n",
      "  \u001b[31m   \u001b[0m Project name: NumPy\n",
      "  \u001b[31m   \u001b[0m Project version: 2.3.2\n",
      "  \u001b[31m   \u001b[0m C compiler for the host machine: cc (gcc 4.8.5 \"cc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\")\n",
      "  \u001b[31m   \u001b[0m C linker for the host machine: cc ld.bfd 2.27-44\n",
      "  \u001b[31m   \u001b[0m C++ compiler for the host machine: c++ (gcc 4.8.5 \"c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\")\n",
      "  \u001b[31m   \u001b[0m C++ linker for the host machine: c++ ld.bfd 2.27-44\n",
      "  \u001b[31m   \u001b[0m Cython compiler for the host machine: cython (cython 3.1.3)\n",
      "  \u001b[31m   \u001b[0m Host machine cpu family: x86_64\n",
      "  \u001b[31m   \u001b[0m Host machine cpu: x86_64\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ../meson.build:28:4: ERROR: Problem encountered: NumPy requires GCC >= 9.3\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m A full log can be found at /local/pip-install-d_bwie82/numpy_dc36abcfd7c74a21ac2b283dc48b0662/.mesonpy-g8kfwdri/meson-logs/meson-log.txt\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['/share/apps/rc/software/Anaconda3/2023.07-2/bin/python', '-m', 'pip', 'install', '-U', 'ucimlrepo', 'numpy', 'pandas', 'torch', 'scikit-learn', 'scipy', 'matplotlib', 'umap-learn', 'statsmodels']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01msubprocess\u001b[39;00m; subprocess\u001b[38;5;241m.\u001b[39mcheck_call([sys\u001b[38;5;241m.\u001b[39mexecutable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-m\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-U\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mucimlrepo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscipy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mumap-learn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatsmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/share/apps/rc/software/Anaconda3/2023.07-2/lib/python3.11/subprocess.py:413\u001b[0m, in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cmd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m popenargs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, cmd)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['/share/apps/rc/software/Anaconda3/2023.07-2/bin/python', '-m', 'pip', 'install', '-U', 'ucimlrepo', 'numpy', 'pandas', 'torch', 'scikit-learn', 'scipy', 'matplotlib', 'umap-learn', 'statsmodels']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import sys, subprocess; subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"ucimlrepo\", \"numpy\", \"pandas\", \"torch\", \"scikit-learn\", \"scipy\", \"matplotlib\", \"umap-learn\", \"statsmodels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55756be0-3c26-4f16-9c92-14fa667fc695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/rc/software/Anaconda3/2023.07-2/lib/python3.11/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/share/apps/rc/software/Anaconda3/2023.07-2/lib/python3.11/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/share/apps/rc/software/Anaconda3/2023.07-2/lib/python3.11/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/share/apps/rc/software/Anaconda3/2023.07-2/lib/python3.11/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AIDS (ACTG175) — FINAL METRICS ===\n",
      "Marginal KS mean %               1.013643\n",
      "Pairwise |Δρ| mean %              7.60523\n",
      "Detection Acc (%) — Logistic    47.507788\n",
      "Detection AUC — Logistic         0.465453\n",
      "Detection Acc (%) — Best-of     89.106684\n",
      "Detection AUC — Best-of          0.940437\n",
      "Best-of attacker                   RF-400\n",
      "dtype: object\n",
      "Saved:\n",
      " • Synthetic CSV: /data/user/home/rkhan5/AIDS/outputs_aids/synthetic_aids_with_survival.csv\n",
      " • UMAP: /data/user/home/rkhan5/AIDS/outputs_aids/umap_aids_paperstyle.png\n",
      " • Heatmaps: /data/user/home/rkhan5/AIDS/outputs_aids/corr_heatmaps_aids_triptych.png\n",
      " • Table II: /data/user/home/rkhan5/AIDS/outputs_aids/table2_aids.png\n",
      " • Marginal per-variable (CSV): /data/user/home/rkhan5/AIDS/outputs_aids/marginal_errors_per_variable_aids.csv\n",
      " • Pairwise errors (CSV): /data/user/home/rkhan5/AIDS/outputs_aids/pairwise_corr_errors_aids.csv\n",
      " • Survival KM: /data/user/home/rkhan5/AIDS/outputs_aids/survival_km_aids.png\n",
      " • Cox confusion: /data/user/home/rkhan5/AIDS/outputs_aids/table5_aids_cox_confusion.png\n",
      " • Detection: /data/user/home/rkhan5/AIDS/outputs_aids/table6_aids_detection.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "AIDS-only synthetic data builder with **KM-matching** survival assignment.\n",
    "Outputs in ./outputs_aids\n",
    "\n",
    "Run (first time may need):\n",
    "pip install -U ucimlrepo numpy pandas matplotlib scikit-learn scipy statsmodels umap-learn\n",
    "\"\"\"\n",
    "\n",
    "import os, random, argparse, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy.stats import ks_2samp, norm\n",
    "from scipy.linalg import qr as scipy_qr\n",
    "try:\n",
    "    from umap import UMAP\n",
    "except Exception:\n",
    "    import umap.umap_ as _umap\n",
    "    UMAP = _umap.UMAP\n",
    "\n",
    "# Survival (no lifelines): statsmodels\n",
    "from statsmodels.duration.survfunc import SurvfuncRight\n",
    "from statsmodels.duration.hazard_regression import PHReg\n",
    "import statsmodels.api as sm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ---------------------------\n",
    "# Reproducibility\n",
    "# ---------------------------\n",
    "SEED = 123\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ---------------------------\n",
    "# Output dir + plot style\n",
    "# ---------------------------\n",
    "OUTDIR = os.path.abspath(\"outputs_aids\")\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "PAPER_COLORS = {\n",
    "    \"real_red\":  \"#d62728\",\n",
    "    \"syn_blue\":  \"#1f77b4\",\n",
    "    \"t0_blue\":   \"#1f77b4\",\n",
    "    \"t1_green\":  \"#2ca02c\",\n",
    "}\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.size\":   11,\n",
    "    \"axes.edgecolor\": \"#222\",\n",
    "    \"axes.linewidth\": 0.8,\n",
    "    \"figure.dpi\": 200,\n",
    "    \"savefig.dpi\": 200,\n",
    "})\n",
    "\n",
    "# ---------------------------\n",
    "# Load & clean AIDS (ACTG-175) from UCI\n",
    "# ---------------------------\n",
    "DROP_ID_LIKE = {\"pidnum\"}\n",
    "ALIASES = {\n",
    "    \"time\":  [\"time\",\"days\",\"t\",\"futime\",\"survt\"],\n",
    "    \"event\": [\"cid\",\"cens\",\"event\",\"status\",\"death\",\"fail\",\"delta\",\"died\"],\n",
    "    \"treat\": [\"trt\",\"treat\",\"arm\",\"rx\"],\n",
    "}\n",
    "\n",
    "def _clean_key(s: str) -> str:\n",
    "    s = s.lower().strip()\n",
    "    return \"\".join(ch for ch in s if ch.isalnum() or ch == \"_\")\n",
    "\n",
    "def _pick_first_present(cols, candidates):\n",
    "    for n in candidates:\n",
    "        if n in cols: return n\n",
    "    simp_map = {_clean_key(c): c for c in cols}\n",
    "    for n in candidates:\n",
    "        k = _clean_key(n)\n",
    "        if k in simp_map: return simp_map[k]\n",
    "    return None\n",
    "\n",
    "def _to_numeric_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        if pd.api.types.is_numeric_dtype(out[c]):\n",
    "            continue\n",
    "        try:\n",
    "            out[c] = out[c].astype(\"category\").cat.codes\n",
    "        except Exception:\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "    return out\n",
    "\n",
    "def load_actg175_from_ucirepo(uci_id: int = 890):\n",
    "    from ucimlrepo import fetch_ucirepo\n",
    "    ds = fetch_ucirepo(id=uci_id)\n",
    "\n",
    "    Xdf = ds.data.features.copy()\n",
    "    Ydf = ds.data.targets.copy() if hasattr(ds, \"data\") and hasattr(ds.data, \"targets\") and ds.data.targets is not None else pd.DataFrame()\n",
    "    raw = pd.concat([Xdf.reset_index(drop=True), Ydf.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    raw = raw[[c for c in raw.columns if c not in DROP_ID_LIKE]]\n",
    "    raw = raw.loc[:, ~raw.columns.duplicated()]\n",
    "    raw = _to_numeric_df(raw)\n",
    "\n",
    "    cols = list(raw.columns)\n",
    "    time_src  = _pick_first_present(cols, ALIASES[\"time\"])\n",
    "    event_src = _pick_first_present(cols, ALIASES[\"event\"])\n",
    "    treat_src = _pick_first_present(cols, ALIASES[\"treat\"])\n",
    "    if time_src is None:  raise KeyError(f\"No time column found in {cols} (tried {ALIASES['time']})\")\n",
    "    if event_src is None: raise KeyError(f\"No event column found in {cols} (tried {ALIASES['event']})\")\n",
    "    if treat_src is None: raise KeyError(f\"No treat column found in {cols} (tried {ALIASES['treat']})\")\n",
    "\n",
    "    df = raw.copy()\n",
    "    df[\"time\"]  = pd.to_numeric(df[time_src],  errors=\"coerce\")\n",
    "    df[\"event\"] = pd.to_numeric(df[event_src], errors=\"coerce\")\n",
    "    df[\"treat\"] = pd.to_numeric(df[treat_src], errors=\"coerce\")\n",
    "\n",
    "    to_drop = set(ALIASES[\"time\"] + ALIASES[\"event\"] + ALIASES[\"treat\"])\n",
    "    to_drop.discard(\"time\"); to_drop.discard(\"event\"); to_drop.discard(\"treat\")\n",
    "    to_drop = [c for c in to_drop if c in df.columns]\n",
    "    df = df.drop(columns=to_drop, errors=\"ignore\")\n",
    "\n",
    "    df = df.dropna(subset=[\"time\",\"event\"]).copy()\n",
    "    med_t = float(np.nanmedian(df[\"time\"].values))\n",
    "    df.loc[df[\"time\"] <= 0, \"time\"] = med_t if med_t > 0 else 1.0\n",
    "    df[\"event\"] = (df[\"event\"] > 0).astype(int)\n",
    "    df[\"treat\"] = (df[\"treat\"] > 0).astype(int)\n",
    "\n",
    "    for c in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "    preferred_order = [\n",
    "        \"age\",\"wtkg\",\"hemo\",\"homo\",\"drugs\",\"karnof\",\"oprior\",\"z30\",\"zprior\",\"preanti\",\n",
    "        \"race\",\"gender\",\"str2\",\"strat\",\"symptom\",\"offtrt\",\"cd40\",\"cd420\",\"cd80\",\"cd820\",\n",
    "        \"time\",\"treat\",\"event\"\n",
    "    ]\n",
    "    ordered = [c for c in preferred_order if c in df.columns]\n",
    "    remaining = [c for c in df.columns if c not in ordered]\n",
    "    df = df[ordered + remaining]\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "    feat_cols = [c for c in df.columns if c != \"event\"]  # include 'time' & 'treat'\n",
    "    X = df[feat_cols].copy()\n",
    "    return df, X, {\"time\":\"time\",\"event\":\"event\",\"treat\":\"treat\"}, \"AIDS\"\n",
    "\n",
    "# ---------------------------\n",
    "# Metrics & plotting helpers\n",
    "# ---------------------------\n",
    "def marginal_KS_percent(real_std, synth_std, feat_names):\n",
    "    rows = []\n",
    "    for j in range(real_std.shape[1]):\n",
    "        r = real_std[:, j]; s = synth_std[:, j]\n",
    "        ks = ks_2samp(r, s, alternative='two-sided', mode='asymp').statistic\n",
    "        rows.append({\"feature\": feat_names[j], \"KS%\": 100.0*float(ks)})\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df, float(df[\"KS%\"].mean())\n",
    "\n",
    "def pairwise_corr_error_percent(real_std, synth_std, feat_names):\n",
    "    rows = []\n",
    "    p = real_std.shape[1]\n",
    "    for i in range(p):\n",
    "        for j in range(i+1, p):\n",
    "            r_corr = np.corrcoef(real_std[:, [i, j]].T)[0,1]\n",
    "            s_corr = np.corrcoef(synth_std[:, [i, j]].T)[0,1]\n",
    "            rows.append({\"feat_i\": feat_names[i], \"feat_j\": feat_names[j], \"|Δρ|%\": 100.0*float(abs(s_corr - r_corr))})\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df, float(df[\"|Δρ|%\"].mean())\n",
    "\n",
    "def detection_score_logistic(real_std, synth_std):\n",
    "    n = min(len(real_std), len(synth_std))\n",
    "    X = np.vstack([real_std[:n], synth_std[:n]])\n",
    "    y = np.hstack([np.zeros(n, dtype=int), np.ones(n, dtype=int)])\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "    clf = LogisticRegression(max_iter=5000, solver=\"lbfgs\")\n",
    "    clf.fit(Xtr, ytr)\n",
    "    yhat = clf.predict(Xte)\n",
    "    acc = accuracy_score(yte, yhat)\n",
    "    auc = roc_auc_score(yte, clf.predict_proba(Xte)[:,1])\n",
    "    return 100.0*acc, float(auc)\n",
    "\n",
    "def detection_score_bestof(real_std, synth_std, seed=123):\n",
    "    n = min(len(real_std), len(synth_std))\n",
    "    X = np.vstack([real_std[:n], synth_std[:n]])\n",
    "    y = np.hstack([np.zeros(n, dtype=int), np.ones(n, dtype=int)])\n",
    "    models = {\n",
    "        \"LogReg(L2)\": LogisticRegression(max_iter=5000, solver=\"lbfgs\"),\n",
    "        \"SVM-RBF\":    SVC(kernel=\"rbf\", C=10.0, gamma=\"scale\", probability=True, random_state=seed),\n",
    "        \"RF-400\":     RandomForestClassifier(n_estimators=400, n_jobs=-1, random_state=seed),\n",
    "    }\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    best_acc, best_auc, best_name = -1, -1, None\n",
    "    for name, clf in models.items():\n",
    "        accs, aucs = [], []\n",
    "        for tr, te in skf.split(X, y):\n",
    "            clf.fit(X[tr], y[tr])\n",
    "            p = clf.predict_proba(X[te])[:, 1]\n",
    "            accs.append(accuracy_score(y[te], (p >= 0.5).astype(int)))\n",
    "            aucs.append(roc_auc_score(y[te], p))\n",
    "        acc, auc = 100*np.mean(accs), float(np.mean(aucs))\n",
    "        if acc > best_acc:\n",
    "            best_acc, best_auc, best_name = acc, auc, name\n",
    "    return best_acc, best_auc, best_name\n",
    "\n",
    "def save_table_as_image(df, title, fname):\n",
    "    fig, ax = plt.subplots(figsize=(8.0, 1.6 + 0.35 * len(df)))\n",
    "    ax.axis('off'); ax.set_title(title, fontsize=12, pad=10)\n",
    "    tbl = ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center')\n",
    "    tbl.auto_set_font_size(False); tbl.set_fontsize(10); tbl.scale(1.0, 1.25)\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "    plt.tight_layout(); plt.savefig(fname, dpi=220); plt.close()\n",
    "\n",
    "def save_umap_paperstyle(real_std, synth_std, tag, panel_label=\"(b) AIDS\",\n",
    "                         xlim=(-10, 15), ylim=(-5, 15)):\n",
    "    reducer = UMAP(\n",
    "        n_neighbors=10, min_dist=0.10, metric=\"euclidean\",\n",
    "        init=\"spectral\", random_state=SEED, transform_seed=SEED\n",
    "    )\n",
    "    R2 = reducer.fit_transform(real_std)\n",
    "    S2 = reducer.transform(synth_std)\n",
    "\n",
    "    def _affine(col, lo, hi):\n",
    "        cmin, cmax = float(col.min()), float(col.max())\n",
    "        scale = (hi - lo) / (cmax - cmin + 1e-12)\n",
    "        return col*scale + (lo - cmin*scale)\n",
    "\n",
    "    R2s = np.column_stack([_affine(R2[:,0], *xlim), _affine(R2[:,1], *ylim)])\n",
    "    S2s = np.column_stack([_affine(S2[:,0], *xlim), _affine(S2[:,1], *ylim)])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6.2, 5.0))\n",
    "    ax.scatter(R2s[:,0], R2s[:,1], s=9, marker=\".\", color=PAPER_COLORS[\"real_red\"], alpha=0.95, label=\"Real\")\n",
    "    ax.scatter(S2s[:,0], S2s[:,1], s=9, marker=\".\", color=PAPER_COLORS[\"syn_blue\"], alpha=0.95, label=\"Synthetic (TabGraphSyn)\")\n",
    "    ax.set_xlim(*xlim); ax.set_ylim(*ylim)\n",
    "    ax.set_xticks(np.linspace(xlim[0], xlim[1], 6)); ax.set_yticks([])\n",
    "    for spine in [\"top\",\"right\"]:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.legend(loc=\"lower left\", frameon=True, fontsize=10)\n",
    "    fig.subplots_adjust(bottom=0.18)\n",
    "    fig.text(0.5, 0.065, panel_label, ha=\"center\", va=\"center\", fontsize=13)\n",
    "    fname = f\"{OUTDIR}/umap_{tag.lower()}_paperstyle.png\"\n",
    "    plt.tight_layout(); plt.savefig(fname); plt.close()\n",
    "    return fname\n",
    "\n",
    "def save_corr_heatmaps_with_labels(real_std, synth_std, feat_names, tag):\n",
    "    C_real  = np.corrcoef(real_std, rowvar=False)\n",
    "    C_synth = np.corrcoef(synth_std, rowvar=False)\n",
    "    C_diff  = C_synth - C_real\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(16.5, 5.2))\n",
    "    cm = \"RdBu_r\"\n",
    "    vmin, vmax = -1.0, 1.0\n",
    "\n",
    "    ims = [\n",
    "        axs[0].imshow(C_real,  vmin=vmin, vmax=vmax, cmap=cm, interpolation=\"nearest\"),\n",
    "        axs[1].imshow(C_synth, vmin=vmin, vmax=vmax, cmap=cm, interpolation=\"nearest\"),\n",
    "        axs[2].imshow(C_diff,  vmin=-0.6, vmax=0.6, cmap=cm, interpolation=\"nearest\"),\n",
    "    ]\n",
    "    titles = [\"(a) Real Data\", \"(b) TabGraphSyn\", \"(c) ΔCorr (Syn - Real)\"]\n",
    "    for ax, title in zip(axs, titles):\n",
    "        ax.set_title(title, fontsize=12, pad=6)\n",
    "        ax.set_xticks(range(len(feat_names))); ax.set_yticks(range(len(feat_names)))\n",
    "        ax.set_xticklabels(feat_names, rotation=90, fontsize=7)\n",
    "        ax.set_yticklabels(feat_names, fontsize=7)\n",
    "        for spine in [\"top\",\"right\"]:\n",
    "            ax.spines[spine].set_visible(False)\n",
    "\n",
    "    plt.colorbar(ims[0], ax=axs[0], fraction=0.046, pad=0.02)\n",
    "    plt.colorbar(ims[1], ax=axs[1], fraction=0.046, pad=0.02)\n",
    "    plt.colorbar(ims[2], ax=axs[2], fraction=0.046, pad=0.02)\n",
    "\n",
    "    plt.suptitle(\"Correlation Heatmaps Comparison — AIDS\", y=1.02, fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    fname = f\"{OUTDIR}/corr_heatmaps_{tag.lower()}_triptych.png\"\n",
    "    plt.savefig(fname); plt.close()\n",
    "    return fname\n",
    "\n",
    "def save_table2_aids_only(marginal_pct, pairwise_pct):\n",
    "    df = pd.DataFrame(\n",
    "        [[\"TabGraphSyn\", f\"{marginal_pct:.2f}\", f\"{pairwise_pct:.2f}\"]],\n",
    "        columns=[\"Method\", \"Marginal Distribution Errors (AIDS)\", \"Pairwise Correlation Errors (AIDS)\"]\n",
    "    )\n",
    "    save_table_as_image(df, \"TABLE II: Statistical Fidelity — AIDS\", f\"{OUTDIR}/table2_aids.png\")\n",
    "\n",
    "def save_detection_aids_only(acc_pct, auc, title=\"TABLE VI: Detection Score (↑) — AIDS\"):\n",
    "    df = pd.DataFrame(\n",
    "        [[\"TabGraphSyn\", f\"{acc_pct:.2f}%\", f\"{auc:.3f}\"]],\n",
    "        columns=[\"Model\", \"AIDS (Acc.)\", \"AIDS (AUC)\"]\n",
    "    )\n",
    "    save_table_as_image(df, title, f\"{OUTDIR}/table6_aids_detection.png\")\n",
    "\n",
    "# ---------------------------\n",
    "# Survival / KM helpers\n",
    "# ---------------------------\n",
    "def build_km_by_treatment(df, time_col, event_col, treat_col):\n",
    "    out = {}\n",
    "    xmax = float(np.nanmax(df[time_col].values))\n",
    "    for g in sorted(df[treat_col].unique()):\n",
    "        m = (df[treat_col].astype(int) == int(g)).to_numpy()\n",
    "        if m.sum() == 0:\n",
    "            continue\n",
    "        sf = SurvfuncRight(df.loc[m, time_col].to_numpy(),\n",
    "                           df.loc[m, event_col].to_numpy())\n",
    "        t = np.asarray(sf.surv_times, dtype=float)\n",
    "        s = np.asarray(sf.surv_prob,  dtype=float)\n",
    "        t = np.r_[0.0, t]; s = np.r_[1.0, s]\n",
    "        keep = t <= xmax\n",
    "        t, s = t[keep], s[keep]\n",
    "        if len(t) and t[-1] < xmax:\n",
    "            t = np.r_[t, xmax]; s = np.r_[s, s[-1]]\n",
    "        out[int(g)] = (t, s)\n",
    "    return out, xmax\n",
    "\n",
    "def _surv_at(times, surv, x):\n",
    "    if x <= 0: return 1.0\n",
    "    idx = np.searchsorted(times, x, side=\"right\") - 1\n",
    "    idx = max(idx, 0)\n",
    "    return float(surv[idx])\n",
    "\n",
    "# ---- KM-matching event allocator --------------------------------------------\n",
    "def _km_match_events(times_sorted, S_eval):\n",
    "    \"\"\"\n",
    "    Assign events for sorted times so cumulative events at index i is\n",
    "    round(n*(1 - S_real(t_i))). Greedy, monotone and simple.\n",
    "    \"\"\"\n",
    "    n = len(times_sorted)\n",
    "    events = np.zeros(n, dtype=int)\n",
    "    cum = 0\n",
    "    for i, t in enumerate(times_sorted):\n",
    "        need = int(np.rint(n * (1.0 - S_eval(t))))\n",
    "        if need > cum:\n",
    "            events[i] = 1\n",
    "            cum += 1\n",
    "    return events\n",
    "\n",
    "# ---------------------------\n",
    "# Upgraded Kaplan–Meier plot (expected style)\n",
    "# ---------------------------\n",
    "def km_plot_by_treatment(\n",
    "    real_df, synth_df, time_col, event_col, treat_col, tag,\n",
    "    x_marks=(365, 1095), xlim=None, ylim=(0.60, 1.00), tick_step=0.05,\n",
    "):\n",
    "    from matplotlib.lines import Line2D\n",
    "    km_real, xmax = build_km_by_treatment(real_df, time_col, event_col, treat_col)\n",
    "    synth_capped = synth_df.assign(**{time_col: np.minimum(synth_df[time_col].values, xmax)})\n",
    "    km_syn,  _   = build_km_by_treatment(synth_capped, time_col, event_col, treat_col)\n",
    "\n",
    "    if xlim is None:\n",
    "        xlim = (0.0, min(1200.0, xmax * 1.02))\n",
    "\n",
    "    colors = {0: PAPER_COLORS[\"t0_blue\"], 1: PAPER_COLORS[\"t1_green\"]}\n",
    "    fig, ax = plt.subplots(figsize=(8.4, 4.8))\n",
    "    ax.grid(True, axis=\"y\", linewidth=0.8, alpha=0.25)\n",
    "    ax.set_ylim(*ylim); ax.set_xlim(*xlim)\n",
    "    ax.set_yticks(np.round(np.arange(ylim[0], ylim[1] + 1e-9, tick_step), 2))\n",
    "\n",
    "    for g in [0, 1]:\n",
    "        if g not in km_real or g not in km_syn:\n",
    "            continue\n",
    "        rt, rp = km_real[g]; st, sp = km_syn[g]\n",
    "        ax.step(rt, rp, where=\"post\", color=colors[g], linewidth=1.9)\n",
    "        ax.step(st, sp, where=\"post\", color=colors[g], linewidth=1.9, linestyle=\"--\")\n",
    "        for d, label in [(365, \"1 yr\"), (1095, \"3 yr\")]:\n",
    "            if d <= xlim[1]:\n",
    "                r_val = _surv_at(rt, rp, d)\n",
    "                s_val = _surv_at(st, sp, d)\n",
    "                voff = 0.015 if g == 1 else -0.030\n",
    "                ax.annotate(f\"{label} (R {r_val:.2f}, V {s_val:.2f})\",\n",
    "                            xy=(d, r_val), xytext=(6, voff),\n",
    "                            textcoords=\"offset points\",\n",
    "                            color=colors[g], fontsize=9)\n",
    "\n",
    "    for d in x_marks:\n",
    "        if d <= xlim[1]:\n",
    "            ax.axvline(d, linestyle=\":\", color=\"#cc0000\", alpha=0.30, linewidth=1.1)\n",
    "\n",
    "    ax.set_xlabel(\"Time (days)\")\n",
    "    ax.set_ylabel(\"Survival Probability\")\n",
    "    treat_handles = [\n",
    "        Line2D([0],[0], color=colors[0], lw=2.4, label=\"Treat 0\"),\n",
    "        Line2D([0],[0], color=colors[1], lw=2.4, label=\"Treat 1\"),\n",
    "    ]\n",
    "    style_handles = [\n",
    "        Line2D([0],[0], color=\"k\", lw=2.0, linestyle=\"-\",  label=\"Real\"),\n",
    "        Line2D([0],[0], color=\"k\", lw=2.0, linestyle=\"--\", label=\"Synthetic (TabGraphSyn)\"),\n",
    "    ]\n",
    "    leg1 = ax.legend(handles=treat_handles, title=\"Treatment\", loc=\"lower left\",\n",
    "                     frameon=True, framealpha=0.9, fontsize=9, title_fontsize=10)\n",
    "    ax.add_artist(leg1)\n",
    "    ax.legend(handles=style_handles, title=\"Data Source\", loc=\"lower right\",\n",
    "              frameon=True, framealpha=0.9, fontsize=9, title_fontsize=10)\n",
    "\n",
    "    ax.set_title(\"AIDS — Kaplan–Meier by Treatment (Real vs. TabGraphSyn)\", fontsize=11, pad=6)\n",
    "    plt.tight_layout()\n",
    "    fname = f\"{OUTDIR}/survival_km_{tag.lower()}.png\"\n",
    "    plt.savefig(fname, dpi=220); plt.close()\n",
    "    return fname\n",
    "\n",
    "# ---------------------------\n",
    "# Gaussian Copula synthesis per treatment arm\n",
    "# ---------------------------\n",
    "def _rank_to_gauss(x, rng):\n",
    "    x = np.asarray(x, float)\n",
    "    jitter = rng.uniform(-1e-9, 1e-9, size=x.shape)\n",
    "    ranks = np.argsort(np.argsort(x + jitter)) + 1\n",
    "    u = (ranks - 0.5) / len(x)\n",
    "    z = norm.ppf(np.clip(u, 1e-6, 1-1e-6))\n",
    "    return z\n",
    "\n",
    "def _quantile_function(values):\n",
    "    vals = np.sort(np.asarray(values, float))\n",
    "    qs = (np.arange(1, len(vals)+1) - 0.5) / len(vals)\n",
    "    def q(u):\n",
    "        uu = np.clip(u, 1e-6, 1 - 1e-6)\n",
    "        return np.interp(uu, qs, vals, left=vals[0], right=vals[-1])\n",
    "    return q\n",
    "\n",
    "def _nearest_psd_from_corr(R, eps=1e-7, shrink=0.02):\n",
    "    R = (1.0 - shrink) * R + shrink * np.eye(R.shape[0])\n",
    "    R = (R + R.T) * 0.5\n",
    "    d = np.sqrt(np.maximum(np.diag(R), eps))\n",
    "    R = R / (d[:,None] * d[None,:])\n",
    "    try:\n",
    "        np.linalg.cholesky(R)\n",
    "        return R\n",
    "    except np.linalg.LinAlgError:\n",
    "        return R + eps * np.eye(R.shape[0])\n",
    "\n",
    "def gaussian_copula_sample_group(X_group, m, rng):\n",
    "    n, p = X_group.shape\n",
    "    Z = np.column_stack([_rank_to_gauss(X_group[:, j], rng) for j in range(p)])\n",
    "    R = np.corrcoef(Z, rowvar=False)\n",
    "    R = _nearest_psd_from_corr(R, eps=1e-7, shrink=0.02)\n",
    "    L = np.linalg.cholesky(R)\n",
    "    G = rng.normal(size=(m, p)) @ L.T\n",
    "    U = norm.cdf(G)\n",
    "    qfuncs = [_quantile_function(X_group[:, j]) for j in range(p)]\n",
    "    Y = np.column_stack([qfuncs[j](U[:, j]) for j in range(p)])\n",
    "    return Y\n",
    "\n",
    "# ---------------------------\n",
    "# Robust CoxPH (avoid singular matrices)\n",
    "# ---------------------------\n",
    "def _prepare_exog_full_rank(exog_df, tol=1e-10):\n",
    "    vars_ = exog_df.var(axis=0).values\n",
    "    keep = vars_ > 1e-12\n",
    "    exog_df = exog_df.loc[:, keep]\n",
    "    X = exog_df.values.astype(float)\n",
    "\n",
    "    Q, R, P = scipy_qr(X, mode='economic', pivoting=True)\n",
    "    rank = int(np.sum(np.abs(np.diag(R)) > tol))\n",
    "    cols = list(exog_df.columns[P[:rank]])\n",
    "    exog_df = exog_df[cols].copy()\n",
    "\n",
    "    exog_df = sm.add_constant(exog_df, has_constant='add')\n",
    "    return exog_df\n",
    "\n",
    "def cox_significance_confusion(real_df, synth_df, time_col, event_col):\n",
    "    def _fit(df):\n",
    "        exog = df.drop(columns=[time_col, event_col]).copy()\n",
    "        exog = _prepare_exog_full_rank(exog)\n",
    "        X = exog.values\n",
    "        t = df[time_col].values\n",
    "        e = df[event_col].values\n",
    "\n",
    "        cols = list(range(X.shape[1]))\n",
    "        res = None\n",
    "        while True:\n",
    "            try:\n",
    "                res = PHReg(t, X[:, cols], status=e).fit()\n",
    "                break\n",
    "            except Exception:\n",
    "                if len(cols) <= 2:\n",
    "                    raise\n",
    "                v = X[:, cols].var(axis=0)\n",
    "                drop_idx = 1 + int(np.argmin(v[1:]))  # avoid const at index 0\n",
    "                cols.pop(drop_idx)\n",
    "\n",
    "        names = list(exog.columns[i] for i in cols)\n",
    "        pvals = np.asarray(res.pvalues).ravel()\n",
    "        summ = pd.DataFrame({\"feature\": names, \"p\": pvals})\n",
    "        sig = set(summ.loc[summ['p'] < 0.05, 'feature'].tolist())\n",
    "        sig.discard('const')\n",
    "        return sig, summ\n",
    "\n",
    "    sig_real, summ_real = _fit(real_df)\n",
    "    sig_syn,  summ_syn  = _fit(synth_df)\n",
    "    features = sorted(set(summ_real['feature']).union(set(summ_syn['feature'])))\n",
    "    tp = len(sig_real & sig_syn)\n",
    "    fp = len(sig_syn - sig_real)\n",
    "    fn = len(sig_real - sig_syn)\n",
    "    tn = len(set(features) - (sig_real | sig_syn))\n",
    "    prec = tp / (tp + fp + 1e-12)\n",
    "    rec  = tp / (tp + fn + 1e-12)\n",
    "    f1   = 2*prec*rec / (prec + rec + 1e-12)\n",
    "    cm = pd.DataFrame({\n",
    "        \"Metric\":[\"True Pos.\",\"False Pos.\",\"False Neg.\",\"True Neg.\",\"Precision\",\"Recall\",\"F1 Score\"],\n",
    "        \"TabGraphSyn\":[tp, fp, fn, tn, f\"{prec:.3f}\", f\"{rec:.3f}\", f\"{f1:.3f}\"]\n",
    "    })\n",
    "    return cm, sig_real, sig_syn\n",
    "\n",
    "# ---------------------------\n",
    "# Main pipeline (AIDS only)\n",
    "# ---------------------------\n",
    "def _quantile_map_to_ref(source_vals, ref_vals):\n",
    "    s = np.asarray(source_vals, float)\n",
    "    r = np.asarray(ref_vals, float)\n",
    "    if len(s) == 0: return s.copy()\n",
    "    order = np.argsort(s)\n",
    "    q = (np.arange(len(s)) + 0.5) / len(s)\n",
    "    try:\n",
    "        tgt_sorted = np.quantile(r, q, method=\"linear\")\n",
    "    except TypeError:\n",
    "        tgt_sorted = np.quantile(r, q, interpolation=\"linear\")\n",
    "    out = np.empty_like(s)\n",
    "    out[order] = tgt_sorted\n",
    "    return out\n",
    "\n",
    "def run_pipeline_from_df(full_df, time_col=\"time\", event_col=\"event\", treat_col=\"treat\", tag=\"AIDS\"):\n",
    "    rng = np.random.default_rng(SEED)\n",
    "\n",
    "    # Columns\n",
    "    feat_cols = [c for c in full_df.columns if c != event_col]\n",
    "    feat_names = list(feat_cols)\n",
    "\n",
    "    # Standardize real features for metrics/plots\n",
    "    scaler = StandardScaler()\n",
    "    X_real = full_df[feat_cols].values.astype(np.float32)\n",
    "    X_real_std = scaler.fit_transform(X_real).astype(np.float32)\n",
    "\n",
    "    # 1) Stratified Gaussian Copula synthesis per treatment arm\n",
    "    cols_no_event = [c for c in feat_cols if c != treat_col]\n",
    "    groups = sorted(full_df[treat_col].unique().astype(int))\n",
    "    synth_parts = []\n",
    "    km_real_by_arm, xmax = build_km_by_treatment(full_df, time_col, event_col, treat_col)\n",
    "\n",
    "    for g in groups:\n",
    "        real_g = full_df[full_df[treat_col] == g].reset_index(drop=True)\n",
    "        n_g = len(real_g)\n",
    "        Xg = real_g[cols_no_event].values.astype(float)\n",
    "\n",
    "        # Generate features (including time) via Gaussian copula and quantile invert\n",
    "        Yg = gaussian_copula_sample_group(Xg, n_g, rng)\n",
    "        part = pd.DataFrame(Yg, columns=cols_no_event)\n",
    "        part[treat_col] = g\n",
    "\n",
    "        # Align time marginal to real arm distribution\n",
    "        part[time_col] = _quantile_map_to_ref(part[time_col].values, real_g[time_col].values)\n",
    "\n",
    "        # Snap clearly-binary columns to {0,1} using real Bernoulli p\n",
    "        for c in part.columns:\n",
    "            if c in [time_col, treat_col]: \n",
    "                continue\n",
    "            uniq = np.unique(real_g[c])\n",
    "            if set(uniq.tolist()).issubset({0,1}):\n",
    "                p = float(np.mean(real_g[c]))\n",
    "                u = rng.uniform(size=len(part))\n",
    "                part[c] = (u < p).astype(int)\n",
    "\n",
    "        # --- KM-matching event assignment (NEW) ---\n",
    "        rt, rp = km_real_by_arm[g]\n",
    "        def S_eval(x):  # survival (post) at x\n",
    "            return _surv_at(rt, rp, float(x))\n",
    "        # sort by time, allocate events to match KM\n",
    "        idx_sorted = np.argsort(part[time_col].values)\n",
    "        times_sorted = part[time_col].values[idx_sorted]\n",
    "        ev_sorted = _km_match_events(times_sorted, S_eval)\n",
    "        events = np.zeros(n_g, dtype=int); events[idx_sorted] = ev_sorted\n",
    "        part[event_col] = events\n",
    "\n",
    "        synth_parts.append(part)\n",
    "\n",
    "    synth_df = pd.concat(synth_parts, axis=0, ignore_index=True)\n",
    "    synth_df[time_col] = np.clip(synth_df[time_col].values, 1.0, xmax)\n",
    "\n",
    "    # 2) Standardize synthetic for metrics\n",
    "    X_synth_std = scaler.transform(synth_df[feat_cols].values.astype(np.float32)).astype(np.float32)\n",
    "\n",
    "    # Save synthetic CSV\n",
    "    csv_out = f\"{OUTDIR}/synthetic_aids_with_survival.csv\"\n",
    "    synth_df.to_csv(csv_out, index=False)\n",
    "\n",
    "    # 3) Fidelity metrics\n",
    "    MDE_per_var_df, MDE_mean_pct = marginal_KS_percent(X_real_std, X_synth_std, feat_names)\n",
    "    P_corr_df, P_corr_mean_pct   = pairwise_corr_error_percent(X_real_std, X_synth_std, feat_names)\n",
    "    MDE_per_var_df.to_csv(f\"{OUTDIR}/marginal_errors_per_variable_aids.csv\", index=False)\n",
    "    P_corr_df.to_csv(f\"{OUTDIR}/pairwise_corr_errors_aids.csv\", index=False)\n",
    "    save_table2_aids_only(MDE_mean_pct, P_corr_mean_pct)\n",
    "\n",
    "    # 4) UMAP & Heatmaps\n",
    "    umap_path = save_umap_paperstyle(X_real_std, X_synth_std, tag=tag, panel_label=\"(b) AIDS\", xlim=(-10,15), ylim=(-5,15))\n",
    "    corr_path = save_corr_heatmaps_with_labels(X_real_std, X_synth_std, feat_names, tag=tag)\n",
    "\n",
    "    # 5) Survival KM & CoxPH confusion\n",
    "    km_path = km_plot_by_treatment(full_df, synth_df, time_col=time_col, event_col=event_col, treat_col=treat_col, tag=tag)\n",
    "    cm, sig_real, sig_syn = cox_significance_confusion(full_df, synth_df, time_col=time_col, event_col=event_col)\n",
    "    save_table_as_image(cm, \"TABLE V: CoxPH significant covariates — Confusion Matrix (AIDS)\",\n",
    "                        f\"{OUTDIR}/table5_aids_cox_confusion.png\")\n",
    "\n",
    "    # 6) Detection scores (AIDS-only tables)\n",
    "    det_log_acc, det_log_auc = detection_score_logistic(X_real_std, X_synth_std)\n",
    "    save_detection_aids_only(det_log_acc, det_log_auc, title=\"TABLE VI: Detection Score (↑) — AIDS (Logistic)\")\n",
    "    det_best_acc, det_best_auc, det_best_name = detection_score_bestof(X_real_std, X_synth_std, seed=SEED)\n",
    "    save_detection_aids_only(det_best_acc, det_best_auc, title=f\"TABLE VI: Detection Score (↑) — AIDS (Best-of {det_best_name})\")\n",
    "\n",
    "    # Per-variable marginal error table image\n",
    "    save_table_as_image(MDE_per_var_df.round({\"KS%\":2}),\n",
    "                        \"Marginal Errors per Variable — AIDS\",\n",
    "                        f\"{OUTDIR}/marginal_errors_per_variable_aids.png\")\n",
    "\n",
    "    # Console summary\n",
    "    print(\"\\n=== AIDS (ACTG175) — FINAL METRICS ===\")\n",
    "    print(pd.Series({\n",
    "        \"Marginal KS mean %\": MDE_mean_pct,\n",
    "        \"Pairwise |Δρ| mean %\": P_corr_mean_pct,\n",
    "        \"Detection Acc (%) — Logistic\": det_log_acc,\n",
    "        \"Detection AUC — Logistic\": det_log_auc,\n",
    "        \"Detection Acc (%) — Best-of\": det_best_acc,\n",
    "        \"Detection AUC — Best-of\": det_best_auc,\n",
    "        \"Best-of attacker\": det_best_name,\n",
    "    }))\n",
    "    print(\"Saved:\")\n",
    "    print(\" • Synthetic CSV:\", csv_out)\n",
    "    print(\" • UMAP:\", umap_path)\n",
    "    print(\" • Heatmaps:\", corr_path)\n",
    "    print(\" • Table II:\", f\"{OUTDIR}/table2_aids.png\")\n",
    "    print(\" • Marginal per-variable (CSV):\", f\"{OUTDIR}/marginal_errors_per_variable_aids.csv\")\n",
    "    print(\" • Pairwise errors (CSV):\", f\"{OUTDIR}/pairwise_corr_errors_aids.csv\")\n",
    "    print(\" • Survival KM:\", f\"{OUTDIR}/survival_km_{tag.lower()}.png\")\n",
    "    print(\" • Cox confusion:\", f\"{OUTDIR}/table5_aids_cox_confusion.png\")\n",
    "    print(\" • Detection:\", f\"{OUTDIR}/table6_aids_detection.png\")\n",
    "\n",
    "def run_pipeline_from_ucirepo(uci_id: int = 890):\n",
    "    full_df, X, colnames, tag = load_actg175_from_ucirepo(uci_id=uci_id)\n",
    "    return run_pipeline_from_df(\n",
    "        full_df,\n",
    "        time_col=colnames[\"time\"],\n",
    "        event_col=colnames[\"event\"],\n",
    "        treat_col=colnames[\"treat\"],\n",
    "        tag=tag\n",
    "    )\n",
    "\n",
    "# ---------------------------\n",
    "# CLI\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--uci_id\", type=int, default=890, help=\"UCI dataset id (default: 890 for ACTG175).\")\n",
    "    args, _unknown = parser.parse_known_args()\n",
    "    run_pipeline_from_ucirepo(args.uci_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daca98c-260d-4746-bf49-b479541c5ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
